{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hahaamg/Generative_AI/blob/main/Week_8/RAG_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG System"
      ],
      "metadata": {
        "id": "POSwdGGQWkPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 從 Google Drive 下載檔案"
      ],
      "metadata": {
        "id": "0NTqnlIfXlEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL='https://drive.google.com/uc?export=download&id=1egucKTAI2gjnfyQrFsrPmpX8WMJHWKZY'\n",
        "!wget -O faiss_db.zip \"$URL\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CntCbb18LQuU",
        "outputId": "161fada1-9028-4d13-b758-c28708eeb24b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-16 16:23:49--  https://drive.google.com/uc?export=download&id=1egucKTAI2gjnfyQrFsrPmpX8WMJHWKZY\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.137.101, 74.125.137.113, 74.125.137.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.137.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1egucKTAI2gjnfyQrFsrPmpX8WMJHWKZY&export=download [following]\n",
            "--2025-04-16 16:23:49--  https://drive.usercontent.google.com/download?id=1egucKTAI2gjnfyQrFsrPmpX8WMJHWKZY&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335560 (328K) [application/octet-stream]\n",
            "Saving to: ‘faiss_db.zip’\n",
            "\n",
            "faiss_db.zip        100%[===================>] 327.70K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-04-16 16:23:51 (4.72 MB/s) - ‘faiss_db.zip’ saved [335560/335560]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhPQD5g0_l5Z",
        "outputId": "169fa804-a936-4a1f-a76b-13a945b55d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  faiss_db.zip\n",
            "   creating: faiss_db/\n",
            "  inflating: faiss_db/index.faiss    \n",
            "  inflating: faiss_db/index.pkl      \n"
          ]
        }
      ],
      "source": [
        "!unzip faiss_db.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc-facvpBkIi"
      },
      "source": [
        "### 安裝並引入必要套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9JThdfm-CVZZ"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-community sentence-transformers faiss-cpu gradio openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L1zqb7F8BMP3"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PTx3Q75QBp_J"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z13eoo6uCnTT"
      },
      "source": [
        "### 自訂 E5 embedding 類別"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HkmvGTaECfTY"
      },
      "outputs": [],
      "source": [
        "class CustomE5Embedding(HuggingFaceEmbeddings):\n",
        "    def embed_documents(self, texts):\n",
        "        texts = [f\"passage: {t}\" for t in texts]\n",
        "        return super().embed_documents(texts)\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        return super().embed_query(f\"query: {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 查看 faiss 基本資訊"
      ],
      "metadata": {
        "id": "Z7vk5o1sX5OC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJfUjzJC63OD",
        "outputId": "b42c83c8-9f78-4d9f-8b35-81951dc7a85e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "向量維度: 384\n",
            "總筆數: 196\n",
            "索引類型: <class 'faiss.swigfaiss_avx512.IndexFlatL2'>\n",
            "前幾筆向量： [[ 0.07144093  0.00418101 -0.07644258 ...  0.05103176  0.07116929\n",
            "   0.06415357]\n",
            " [ 0.08832071  0.02076687 -0.08648844 ...  0.07845695  0.05574175\n",
            "   0.06062891]\n",
            " [ 0.09389171 -0.01096293 -0.06845181 ...  0.08108832  0.07432593\n",
            "   0.05513625]\n",
            " [ 0.08489361  0.00102893 -0.07083521 ...  0.06170662  0.06771576\n",
            "   0.05746834]\n",
            " [ 0.05797962 -0.02049389 -0.05799684 ...  0.06483547  0.04998692\n",
            "   0.05814803]]\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "\n",
        "# 載入 index\n",
        "index = faiss.read_index(\"faiss_db/index.faiss\")\n",
        "\n",
        "# 印出基本資訊\n",
        "print(\"向量維度:\", index.d)\n",
        "print(\"總筆數:\", index.ntotal)\n",
        "print(\"索引類型:\", type(index))\n",
        "\n",
        "# 例如取出前 5 筆向量（如果有的話）\n",
        "vectors = index.reconstruct_n(0, min(5, index.ntotal))\n",
        "print(\"前幾筆向量：\", vectors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkXNMQs5RbNG"
      },
      "source": [
        "### 載入 `faiss_db`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkELACdWCtpo"
      },
      "outputs": [],
      "source": [
        "embedding_model = CustomE5Embedding(model_name=\"intfloat/multilingual-e5-small\")\n",
        "db = FAISS.load_local(\"faiss_db\", embedding_model, allow_dangerous_deserialization=True)\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrHSAsjcRkXF"
      },
      "source": [
        "### 設定 LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qefbHOaUDUvR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xefdy-lkRtAL"
      },
      "outputs": [],
      "source": [
        "api_key = userdata.get('Groq')\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "654I7y52R8yO"
      },
      "source": [
        "這裡的模型和 `base_url` 是用 Groq, 如果用其他服務請自行修改。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sqWfH90JFFWV"
      },
      "outputs": [],
      "source": [
        "model = \"llama3-70b-8192\"\n",
        "# model = \"gemma3:27b\"\n",
        "base_url=\"https://api.groq.com/openai/v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JnqlH0W9P2-Q"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    base_url=base_url # 使用 OpenAI 本身不需要這段\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0egxeawSR41"
      },
      "source": [
        "### Prompt 設計"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZaUnqDpfFop-"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"你是部落格的內容行銷專員，請根據資料來回應的問題。請親切、簡潔並附帶具體建議。請用繁體中文回應。\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "你是一位資深的知識專家助理，擅長用繁體中文從文件中找出重點並加以整合說明。\n",
        "\n",
        "以下是知識庫中找到的資訊片段（可能來自不同文件）請你閱讀全部資訊後，再進行統整，不要只選擇部分資料作答：\n",
        "-------------------------------------\n",
        "{retrieved_chunks}\n",
        "-------------------------------------\n",
        "\n",
        "請根據上方資料，完整、有條理地回答使用者的問題。\n",
        "1. 若資訊足夠，請詳細解釋並輔以舉例。\n",
        "2. 若資訊不足，也請指出無法回答的原因。\n",
        "\n",
        "使用者的提問如下：\n",
        "{question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw8azlVESghL"
      },
      "source": [
        "### 6. 使用 RAG 來回應\n",
        "\n",
        "搜尋與使用者問題相關的資訊，根據我們的 prompt 樣版去讓 LLM 回應。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pWfDUb3mD-6X"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "\n",
        "def chat_with_rag(user_input):\n",
        "    global chat_history\n",
        "    # 取回相關資料\n",
        "    # 從向量資料庫（FAISS）中取回幾筆最相關的資料片段（documents）\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": 10})  # 可拉高為 8~10\n",
        "    docs = retriever.get_relevant_documents(user_input)\n",
        "    #retrieved_chunks = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "    retrieved_chunks = \"\\n\\n\".join([f\"[來源 {i+1}]\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n",
        "\n",
        "\n",
        "    # 將自定 prompt 套入格式\n",
        "    final_prompt = prompt_template.format(retrieved_chunks=retrieved_chunks, question=user_input)\n",
        "\n",
        "    # 呼叫 OpenAI API\n",
        "    response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": final_prompt},\n",
        "    ],\n",
        "    max_tokens=1536,  # 加大 token 數量，可更大\n",
        "    temperature=0.7\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    chat_history.append((user_input, answer))\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m7E7XmgTJUr"
      },
      "source": [
        "### 7. 用 Gradio 打造 Web App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "YI5swv4AFa_U",
        "outputId": "8d680578-d067-4e4e-da5a-cc0e63ce56c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-97962c0479b6>:3: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://78b8451609f77c3198.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://78b8451609f77c3198.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-fd88f73e8364>:8: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(user_input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://78b8451609f77c3198.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# AI 部落格內容管理\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(placeholder=\"請輸入你的問題...\")\n",
        "\n",
        "    def respond(message, chat_history_local):\n",
        "        response = chat_with_rag(message)\n",
        "        chat_history_local.append((message, response))\n",
        "        return \"\", chat_history_local\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Tvhd9jYKFeGR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}