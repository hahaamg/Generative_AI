{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hahaamg/Generative_AI/blob/main/Week11/Stable_Diffusion_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLEQCNfkBxm6"
      },
      "source": [
        "# Stable Diffusion WebUI\n",
        "\n",
        "### å®‰è£å¿…è¦å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50QsZ9LcBw5Y",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install diffusers transformers accelerate safetensors huggingface_hub gradio --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "éƒ¨åˆ†æ¨¡å‹éœ€è¦ Hugging Face tokenï¼ˆaccess keyï¼‰"
      ],
      "metadata": {
        "id": "an6-Ceh6QKtc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3YMEdSZB98I"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "login(token=hf_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxCcNOPBCmf2"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler, DiffusionPipeline\n",
        "import torch\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NhvpxxqCqps"
      },
      "source": [
        "### Hugging Face Model Hub æ‰¾æ¨¡å‹\n",
        "æ¨¡å‹ï¼šnitrosocke/spider-verse-diffusionï¼ˆå‰åœåŠ›é¢¨æ ¼ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy2-xjIyCpbI"
      },
      "outputs": [],
      "source": [
        "model_name = \"nitrosocke/redshift-diffusion\"\n",
        "\n",
        "#\n",
        "\n",
        "# ---- é€™å€‹æ¨¡å‹é¢¨æ ¼ç‰¹åˆ¥ä½†æ˜¯ LoRA ä¸”æœƒçˆ† RAM ----\n",
        "\n",
        "# https://huggingface.co/strangerzonehf/2DAura-Flux\n",
        "# https://huggingface.co/alvdansen/pola-photo-flux\n",
        "# https://huggingface.co/strangerzonehf/Gem-Touch-LoRA-Flux\n",
        "# https://huggingface.co/artificialguybr/logo-redmond-1-5v-logo-lora-for-liberteredmond-sd-1-5\n",
        "# https://huggingface.co/strangerzonehf/Flux-Master-Claymation\n",
        "\n",
        "#digiplay/majicMIX_realistic_v6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "æ³¨æ„æœ‰å¯èƒ½è¦åœç”¨ `use_safetensors=True`\n",
        "\n"
      ],
      "metadata": {
        "id": "cfsSUkxlUpsi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4fEdszfCyO7"
      },
      "outputs": [],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    # use_safetensors=True # å¦‚æœæ¨¡å‹æ”¯æ´ï¼Œé€™æ¨£å¯ä»¥åŠ å¿«è¼‰å…¥\n",
        ").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzzFo2qCC56V"
      },
      "outputs": [],
      "source": [
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4ZAPdMsC_Dq"
      },
      "source": [
        "### 3. ç”Ÿæˆçš„å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpPjwVKbDEKe"
      },
      "outputs": [],
      "source": [
        "def generate_images(prompt, use_enhance, enhance_text, use_negative, negative_text,\n",
        "                    use_custom_seed, custom_seed, height, width, steps, num_images):\n",
        "\n",
        "    height = int(height)\n",
        "    width = int(width)\n",
        "\n",
        "    if height % 8 != 0 or width % 8 != 0:\n",
        "        raise ValueError(\"é«˜åº¦å’Œå¯¬åº¦å¿…é ˆæ˜¯8çš„å€æ•¸ï¼\")\n",
        "\n",
        "    if use_custom_seed:\n",
        "        base_seed = int(custom_seed)\n",
        "    else:\n",
        "        base_seed = random.randint(0, 2**32 - 1)\n",
        "\n",
        "    seeds = [base_seed + i for i in range(num_images)]\n",
        "\n",
        "    prompts = []\n",
        "    negative_prompts = []\n",
        "    generators = []\n",
        "\n",
        "    final_prompt = prompt\n",
        "    if use_enhance and enhance_text:\n",
        "        final_prompt = prompt + \", \" + enhance_text\n",
        "\n",
        "    final_negative = negative_text if use_negative else None\n",
        "\n",
        "    for seed in seeds:\n",
        "        g = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "        generators.append(g)\n",
        "        prompts.append(final_prompt)\n",
        "        negative_prompts.append(final_negative)\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    images = []\n",
        "    for i in range(num_images):\n",
        "        with torch.no_grad():\n",
        "            image = pipe(\n",
        "                prompt=prompts[i],\n",
        "                negative_prompt=negative_prompts[i] if final_negative else None,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=7.5,\n",
        "                generator=generators[i]\n",
        "            ).images[0]\n",
        "            images.append(image)\n",
        "\n",
        "    return images, f\"ä½¿ç”¨çš„ random seeds: {seeds}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKiTPYpWDVln"
      },
      "source": [
        "### 4. æ‰“é€  Gradio Web App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uJnUGTXDOCN"
      },
      "outputs": [],
      "source": [
        "default_enhance = \"masterpiece, ultra high quality, intricate skin details, cinematic lighting\"\n",
        "default_negative = \"soft blurry, bad anatomy, blurry, disfigured, poorly drawn hands, extra fingers, mutated hands, low quality, worst quality\"\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Default(primary_hue=\"red\", secondary_hue=\"pink\")) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¨ å‰åœåŠ›é¢¨æ ¼åœ–åƒç”Ÿæˆå™¨\n",
        "    æ­¡è¿ä½¿ç”¨ï¼è¼¸å…¥æç¤ºè©ã€é¸æ“‡è¨­å®šï¼Œç«‹å³ç”Ÿæˆä½ çš„å¯«å¯¦é¢¨æ ¼ä½œå“ï¼\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=6):\n",
        "            prompt = gr.Textbox(label=\"Prompt\", placeholder=\"è«‹è¼¸å…¥ä½ çš„æç¤ºè© (prompt)\",value=\"ghibli style....\", lines=3)\n",
        "            with gr.Row():\n",
        "                use_enhance = gr.Checkbox(label=\"åŠ å¼· Prompt\", value=True)\n",
        "                enhance_text = gr.Textbox(label=\"åŠ å¼·å…§å®¹\", value=default_enhance)\n",
        "            with gr.Row():\n",
        "                use_negative = gr.Checkbox(label=\"ä½¿ç”¨ Negative Prompt\", value=True)\n",
        "                negative_text = gr.Textbox(label=\"Negative Prompt å…§å®¹\", value=default_negative)\n",
        "            with gr.Row():\n",
        "                use_custom_seed = gr.Checkbox(label=\"è‡ªè¨‚ Random Seed\", value=False)\n",
        "                custom_seed = gr.Number(label=\"æŒ‡å®š seed (é¸å¡«)\", value=42)\n",
        "            with gr.Row():\n",
        "                height = gr.Dropdown([\"512\", \"768\", \"1024\"], label=\"é«˜åº¦ Height\", value=\"512\")\n",
        "                width = gr.Dropdown([\"512\", \"768\", \"1024\"], label=\"å¯¬åº¦ Width\", value=\"768\")\n",
        "            with gr.Row():\n",
        "                steps = gr.Slider(10, 50, value=20, step=5, label=\"ç”Ÿæˆæ­¥æ•¸ (Steps)\")\n",
        "                num_images = gr.Slider(1, 4, step=1, value=1, label=\"ç”Ÿæˆå¼µæ•¸\")\n",
        "            generate_btn = gr.Button(\"ğŸš€ é–‹å§‹ç”Ÿæˆï¼\")\n",
        "\n",
        "        with gr.Column(scale=6):\n",
        "            gallery = gr.Gallery(label=\"ç”Ÿæˆçµæœ\", columns=2, object_fit=\"contain\", height=\"auto\")\n",
        "            seed_info = gr.Label(label=\"ä½¿ç”¨çš„ Random Seeds\")\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generate_images,\n",
        "        inputs=[prompt, use_enhance, enhance_text, use_negative, negative_text,\n",
        "                use_custom_seed, custom_seed, height, width, steps, num_images],\n",
        "        outputs=[gallery, seed_info]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYR6wPYHDmkn"
      },
      "outputs": [],
      "source": [
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}